{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import backend as kb\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Flatten, Lambda, Concatenate, Reshape, LSTM, RepeatVector, SimpleRNN, Activation, Dense\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from os.path import expanduser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.load('/srv/scratch/mmwave/Testing_Set/Falling/sample0/sample_data.npy', allow_pickle=True)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(expanduser(\"~\") + '/data_analysis_mmwave')\n",
    "os.chdir(expanduser(\"~\") + '/data_analysis_mmwave')\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "disable_eager_execution() # toggle on and off based on if u have training/validation\n",
    "\n",
    "# INITIAL VALUES\n",
    "epochs = 100\n",
    "ARRAY_CHUNKS = 1000\n",
    "frame_window_size = 20\n",
    "TIMESTAMP = 0\n",
    "X = 2\n",
    "Y = 3\n",
    "Z = 4\n",
    "DOPPLER = 5\n",
    "MAX_POINT_FRAME = -1\n",
    "STEP_SIZE = 1\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/scratch/mmwave/\n"
     ]
    }
   ],
   "source": [
    "# removing test set from input\n",
    "#\n",
    "os.getcwd()\n",
    "# scratch\n",
    "ADL_Directories = os.listdir('/srv/scratch/mmwave/Data_Input/')\n",
    "# local\n",
    "# ADL_Directories = os.listdir('Data_Input/')\n",
    "ADL_Directories.remove('Falling')\n",
    "Falling_Directories = ['Falling']\n",
    "# this will define where the data is located\n",
    "# scratch\n",
    "shared_drive_prefix = '/srv/scratch/mmwave/'\n",
    "# local\n",
    "#shared_drive_prefix = ''\n",
    "\n",
    "\n",
    "Array_DIR_Train = shared_drive_prefix\n",
    "Array_DIR_Test = shared_drive_prefix\n",
    "Frame_DIR_Stats = \"Frame_Statistics/\"\n",
    "Training_DIR = \"Training_Results/\"\n",
    "print(Array_DIR_Train)\n",
    "\n",
    "if os.path.exists(Array_DIR_Train) is False:\n",
    "    os.mkdir(Array_DIR_Train)\n",
    "if os.path.exists(Frame_DIR_Stats) is False:\n",
    "    os.mkdir(Frame_DIR_Stats)\n",
    "if os.path.exists(Array_DIR_Test) is False:\n",
    "    os.mkdir(Array_DIR_Test)\n",
    "if os.path.exists(Training_DIR) is False:\n",
    "    os.mkdir(Training_DIR)\n",
    "if os.path.exists(\"/srv/scratch/mmwave/Checkpoints/\") is False:\n",
    "    os.mkdir(\"/srv/scratch/mmwave/Checkpoints/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Frame Statistic block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frame_statistics(train, test):\n",
    "    max = -1\n",
    "    min = 10000000\n",
    "    average = 0\n",
    "    histogram = {}\n",
    "    count = 0\n",
    "    for sample in train:\n",
    "        for frame in sample.keys():\n",
    "            histogram[frame] = len(sample[frame])\n",
    "            average = average + len(sample[frame])\n",
    "            count = count + 1\n",
    "            if(len(sample[frame]) > max):\n",
    "                max = len(sample[frame])\n",
    "            if(len(sample[frame]) < min):\n",
    "                min = len(sample[frame])\n",
    "\n",
    "    for sample in test:\n",
    "        for frame in sample.keys():\n",
    "            histogram[frame] = len(sample[frame])\n",
    "            average = average + len(sample[frame])\n",
    "            count = count + 1\n",
    "            if(len(sample[frame]) > max):\n",
    "                max = len(sample[frame])\n",
    "            if(len(sample[frame]) < min):\n",
    "                min = len(sample[frame])\n",
    "    with open(Frame_DIR_Stats + 'Frame_Histogram.json', 'w') as file:\n",
    "        json.dump(histogram, file)\n",
    "    with open(Frame_DIR_Stats + 'max_frame_size.json', 'w') as file:\n",
    "        json.dump({\"max\": max, \"min\": min, \"average\": average/count}, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_histogram():\n",
    "    histogram = {}\n",
    "    with open(Frame_DIR_Stats + 'Frame_Histogram.json', 'r') as file:\n",
    "        histogram = json.load(file)\n",
    "    pyplot.hist(list(histogram.values()))\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_max():\n",
    "    if(os.path.exists(Frame_DIR_Stats + 'max_frame_size.json') is False):\n",
    "        print(\"PLEASE UNCOMMENT THE STATISTICS BLOCK BELOW BEFORE RUNNING ANY OF THIS\")\n",
    "    stats = {}\n",
    "    with open(Frame_DIR_Stats + 'max_frame_size.json', 'r') as file:\n",
    "        stats = json.load(file)\n",
    "    return stats['max']\n",
    "MAX_POINT_FRAME = retrieve_max()\n",
    "MAX_POINT_FRAME = MAX_POINT_FRAME + (16 - (MAX_POINT_FRAME % 16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frame_sequences(raw_data_samples):\n",
    "    frame_map_array = []\n",
    "    count = 0\n",
    "    sample_string = \"sample_\" + str(count)\n",
    "    for sample in raw_data_samples:\n",
    "        frame_map = {}\n",
    "        for data in sample:\n",
    "            timestamp = data[TIMESTAMP]+\"_\"+sample_string\n",
    "            if timestamp in frame_map:\n",
    "                frame_map[timestamp].append(np.array(data[[X, Y, Z, DOPPLER]]))\n",
    "            else:\n",
    "                frame_map[timestamp] = []\n",
    "                frame_map[timestamp].append(np.array(data[[X, Y, Z, DOPPLER]]))\n",
    "        count = count + 1\n",
    "        sample_string = \"sample_\" + str(count)\n",
    "        frame_map_array.append(frame_map)\n",
    "    return frame_map_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_raw_data_sliding_window(Directory):\n",
    "#     # want to load into samples vs a single dump\n",
    "#     raw_data = []\n",
    "#     for activity in Directory:\n",
    "#         if activity == \"Transitions\":\n",
    "#             for transition in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity):\n",
    "#                 for orientation in os.listdir('/srv/scratch/mmwave/Data_Input/' + \"/\" + activity + \"/\" + transition):\n",
    "#                     for subject in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity + \"/\" + transition + \"/\" + orientation):\n",
    "#                         data = pd.read_csv(\n",
    "#                             '/srv/scratch/mmwave/Data_Input/' + activity + \"/\" + transition + \"/\" + orientation + \"/\" + subject + \"/points_cloud.csv\")\n",
    "#                         raw_data.append(data.to_numpy())\n",
    "#         else:\n",
    "#             for orientation in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity):\n",
    "#                 for subject in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity + \"/\" + orientation):\n",
    "#                     if not os.path.exists('/srv/scratch/mmwave/Data_Input/' + activity + \"/\" +\n",
    "#                                        orientation + \"/\" + subject + \"/points_cloud.csv\"):\n",
    "#                         continue\n",
    "#                     data = pd.read_csv('/srv/scratch/mmwave/Data_Input/' + activity + \"/\" +\n",
    "#                                        orientation + \"/\" + subject + \"/points_cloud.csv\")\n",
    "#                     raw_data.append(data.to_numpy())\n",
    "#     return raw_data\n",
    "def load_raw_data_sliding_window(Directory):\n",
    "    # want to load into samples vs a single dump\n",
    "    raw_data = []\n",
    "    for activity in Directory:\n",
    "        if activity == \"Transitions\":\n",
    "            for transition in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity):\n",
    "                for orientation in os.listdir('/srv/scratch/mmwave/Data_Input/' + \"/\" + activity + \"/\" + transition):\n",
    "                    for subject in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity + \"/\" + transition + \"/\" + orientation):\n",
    "                        data = pd.read_csv(\n",
    "                            '/srv/scratch/mmwave/Data_Input/' + activity + \"/\" + transition + \"/\" + orientation + \"/\" + subject + \"/points_cloud.csv\")\n",
    "                        raw_data.append(data.to_numpy())\n",
    "        else:\n",
    "            for file in os.listdir('/srv/scratch/mmwave/Data_Input/' + activity):\n",
    "                data = pd.read_csv('/srv/scratch/mmwave/Data_Input/' + activity +\n",
    "                    \"/\" + file)\n",
    "                raw_data.append(data.to_numpy())\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this method will process raw data, by oversampling the raw data with the proposed oversampling technique and proceed to\n",
    "save the data to disk. it will only process unprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_float_string(input):\n",
    "    try:\n",
    "        float(input)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_junk(all_frames):\n",
    "    clean_frames = []\n",
    "    for frame in all_frames:\n",
    "        add = True\n",
    "        for point in frame:\n",
    "            if not check_if_float_string(point[0]) or not check_if_float_string(point[1]) or not check_if_float_string(point[2]) or not check_if_float_string(point[3]):\n",
    "                add = False\n",
    "        if(add):\n",
    "            clean_frames.append(frame)\n",
    "    return clean_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_and_save_remaining_frames(frame_sequences, saved_array_parts, Array_DIR, TrainTest):\n",
    "    sample_count = saved_array_parts\n",
    "    for sample in frame_sequences[saved_array_parts:]:\n",
    "        count = 0\n",
    "        last_loaded_array_index = saved_array_parts\n",
    "        all_frames = []\n",
    "        for frame in sample.values():\n",
    "            all_frames.append(frame)\n",
    "        all_frames = remove_junk(all_frames)\n",
    "        if(len(all_frames) == 0):\n",
    "            continue;\n",
    "        # pad if we are below window size\n",
    "        while len(all_frames) <= frame_window_size:\n",
    "            all_frames.append(np.zeros(np.shape(all_frames[0])))\n",
    "        frame_sequence_array = []\n",
    "        for i in range(0, len(all_frames) - frame_window_size, STEP_SIZE):\n",
    "            frame_sequence_array.append([np.squeeze([all_frames[i:(i+frame_window_size)]])])\n",
    "        # if there is still data to process, start from last save point\n",
    "        processed_oversampled_frames_array = []\n",
    "        processed_oversampled_frames = []\n",
    "        for frame_batch in frame_sequence_array:\n",
    "            batch = []\n",
    "            for frame in np.squeeze(frame_batch):\n",
    "                frame_sampled = oversample(frame)\n",
    "                batch.append(np.array(frame_sampled))\n",
    "            processed_oversampled_frames.append(np.array(batch))\n",
    "            count += 1\n",
    "        if os.path.exists(Array_DIR + TrainTest + \"/\") is False:\n",
    "            os.mkdir(Array_DIR + TrainTest + \"/\")\n",
    "        if os.path.exists(Array_DIR + TrainTest +\"/sample\"+str(sample_count)) is False:\n",
    "            os.mkdir(Array_DIR + TrainTest +\"/sample\"+str(sample_count)+\"/\")\n",
    "        frames_backup = []\n",
    "        for val in processed_oversampled_frames:\n",
    "            if (np.shape(val) == (20,272,4)):\n",
    "                frames_backup.append(val)\n",
    "        processed_oversampled_frames = frames_backup\n",
    "        np.save(Array_DIR + TrainTest +\"/sample\"+str(sample_count)+\"/sample_data\", np.array(\n",
    "                    processed_oversampled_frames), allow_pickle=True, fix_imports=True)\n",
    "        sample_count = sample_count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will load any data that is saved during raw data processing, this saves time making sure there is no duplicate pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_array_data(saved_array_parts, Array_Dir, TrainTest):\n",
    "    processed_oversampled_frames = []\n",
    "    clean_frames = []\n",
    "    if saved_array_parts > 0:\n",
    "        for i in range(saved_array_parts):\n",
    "            array_part = np.load(Array_Dir + TrainTest + \"sample\"+ str(i)+\"/sample_data\" + \".npy\", allow_pickle=True)\n",
    "            clean_frames.append(np.array(array_part).astype('float64'))\n",
    "#             clean_frames.append(np.array(array_part).astype('float64')/255.0)\n",
    "            processed_oversamples_frames = []\n",
    "    return clean_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_t, y_p, output_mean, output_log_variance):\n",
    "    batch_size = kb.int_shape(y_t)[0]\n",
    "    number_of_frames = kb.int_shape(y_t)[1]\n",
    "    number_of_features = kb.int_shape(y_t)[-1]\n",
    "    predicted_mean = y_p[:, :, :, :number_of_features]\n",
    "    predicted_log_variance = y_p[:, :, :, number_of_features:]\n",
    "    predicted_variance = kb.exp(predicted_log_variance)\n",
    "\n",
    "    true_reshape = kb.reshape(y_t, (batch_size, number_of_frames, -1))\n",
    "    mean_reshape = kb.reshape(\n",
    "        predicted_mean, (batch_size, number_of_frames, -1))\n",
    "    variance_reshape = kb.reshape(\n",
    "        predicted_variance, (batch_size, number_of_frames, -1))\n",
    "    log_variance_reshape = kb.reshape(\n",
    "        predicted_log_variance, (batch_size, number_of_frames, -1))\n",
    "    true_reshape = tf.cast(true_reshape, tf.float32)\n",
    "    mean_reshape = tf.cast(mean_reshape, tf.float32)\n",
    "    \n",
    "    log_output = (kb.square(true_reshape - mean_reshape))/variance_reshape\n",
    "    log_output = kb.sum(0.5*log_output, axis=-1)\n",
    "    KL_loss = -0.5*kb.sum(1 + output_log_variance -\n",
    "                          kb.square(output_mean) - kb.exp(output_log_variance), axis=-1)\n",
    "    \n",
    "    return kb.mean(log_output + KL_loss, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(inputs):\n",
    "    input_mean, input_log_variance = inputs\n",
    "    batch_size = kb.shape(input_mean)[0]\n",
    "    number_of_frames = kb.int_shape(input_mean)[1]\n",
    "    latent_dimension = kb.int_shape(input_mean)[2]\n",
    "    epsilon = kb.random_normal(shape=(\n",
    "        batch_size, number_of_frames, latent_dimension), mean=0., stddev=1.0, seed=None)\n",
    "    return input_mean + kb.exp(0.5*input_log_variance) * epsilon"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data):\n",
    "    data = np.array(data, dtype=np.float64)\n",
    "    if(len(data) == 0):\n",
    "        return []\n",
    "    number_of_points = MAX_POINT_FRAME\n",
    "    axis = np.shape(data)[0]\n",
    "    mean = np.mean(data, axis=0)\n",
    "    frame_np = np.sqrt(number_of_points/axis)*data + \\\n",
    "        mean - np.sqrt(number_of_points/axis)*mean\n",
    "    oversampled_frame = frame_np.tolist()\n",
    "    oversampled_frame.extend([mean]*(number_of_points-axis))\n",
    "    oversampled_return = np.array(oversampled_frame)\n",
    "    return oversampled_return"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Loading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mmData(Directory, TrainTest, Array_DIR):\n",
    "    point_cloud_scatter_samples = load_raw_data_sliding_window(Directory)\n",
    "    frame_sequences = generate_frame_sequences(point_cloud_scatter_samples)\n",
    "    if os.path.exists(Array_DIR + TrainTest) is False:\n",
    "        os.makedirs(Array_DIR + TrainTest)\n",
    "    saved_array_parts = len(os.listdir(Array_DIR + TrainTest))\n",
    "    oversample_and_save_remaining_frames(\n",
    "        frame_sequences, saved_array_parts, Array_DIR, TrainTest)\n",
    "    return load_saved_array_data(saved_array_parts, Array_DIR, TrainTest)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODEL TRAINING CELLS BELOW\n",
    "_________________________________________________________________________\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load the Necessary packages and set tensorflow to cpu-only for meanwhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_HVRNNAE(training_set, testing_set):\n",
    "    print(\"training_started\")\n",
    "    number_of_frames = frame_window_size\n",
    "    number_of_points = MAX_POINT_FRAME\n",
    "    number_of_features = 4\n",
    "\n",
    "    encoding_dimension = MAX_POINT_FRAME\n",
    "    latent_dimension = 16\n",
    "    inputs = Input(\n",
    "        shape=(number_of_frames, number_of_points, number_of_features))\n",
    "    input_flatten = TimeDistributed(Flatten(None))(inputs)\n",
    "    input_flatten = TimeDistributed(Dense(encoding_dimension, activation='tanh'))(input_flatten)\n",
    "    input_mean = TimeDistributed(\n",
    "        Dense(latent_dimension, activation=None), name='input_mean')(input_flatten)\n",
    "    input_log_variance = TimeDistributed(\n",
    "        Dense(latent_dimension, activation=None, kernel_initializer=initializers.Zeros()), name='input_log_variance')(input_flatten)\n",
    "    sampled_input = Lambda(sample)([input_mean, input_log_variance])\n",
    "\n",
    "    encoder = SimpleRNN(latent_dimension, activation='tanh',\n",
    "                        return_sequences=False)(sampled_input)\n",
    "    repeat_encoder = RepeatVector(number_of_frames)(encoder)\n",
    "    decoder_RNN = SimpleRNN(\n",
    "        latent_dimension, activation='tanh', return_sequences=True)(repeat_encoder)\n",
    "    decoder = Lambda(lambda x: tf.reverse(x, axis=[-2]))(decoder_RNN)\n",
    "\n",
    "    latent_input = TimeDistributed(\n",
    "        Dense(encoding_dimension, activation='tanh'))(decoder)\n",
    "    latent_mean = TimeDistributed(\n",
    "        Dense(number_of_features, activation=None))(latent_input)\n",
    "    latent_log_variance = TimeDistributed(\n",
    "        Dense(number_of_features, activation=None))(latent_input)\n",
    "\n",
    "    output = Concatenate()([latent_mean, latent_log_variance])\n",
    "    output = TimeDistributed(RepeatVector(number_of_points))(output)\n",
    "    outputs = TimeDistributed(\n",
    "        Reshape((number_of_points, number_of_features*2)), name='test')(output)\n",
    "\n",
    "    def HVRNNAE_loss(y_t, y_p):\n",
    "        batch_size = kb.shape(y_t)[0]\n",
    "        number_of_frames = kb.shape(y_t)[1]\n",
    "        number_of_features = kb.shape(y_t)[-1]\n",
    "\n",
    "        predicted_mean = y_p[:, :, :, :number_of_features]\n",
    "        predicted_log_variance = y_p[:, :, :, number_of_features:]\n",
    "        predicted_variance = kb.exp(predicted_log_variance)\n",
    "\n",
    "        true_reshape = kb.reshape(y_t, (batch_size, number_of_frames, -1))\n",
    "        mean_reshape = kb.reshape(\n",
    "            predicted_mean, (batch_size, number_of_frames, -1))\n",
    "        variance_reshape = kb.reshape(\n",
    "            predicted_variance, (batch_size, number_of_frames, -1))\n",
    "        log_variance_reshape = kb.reshape(\n",
    "            predicted_log_variance, (batch_size, number_of_frames, -1))\n",
    "\n",
    "        log_output = (kb.square(true_reshape - mean_reshape))/variance_reshape\n",
    "        log_output = kb.sum(0.5*log_output, axis=-1)\n",
    "\n",
    "        KL_loss = -0.5*kb.sum(1 + input_log_variance -\n",
    "                              kb.square(input_mean) - kb.exp(input_log_variance), axis=-1)\n",
    "        return kb.mean(log_output + KL_loss)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    optimiser = optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad=False)\n",
    "    model.compile(optimizer=optimiser, loss=HVRNNAE_loss)\n",
    "    checkpoint_path = \"/srv/scratch/mmwave/Checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "    last_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    print(\"LAST CHECKPOINT -  \", last_checkpoint)\n",
    "    remaining_epochs = epochs\n",
    "    i_epoch = 0\n",
    "    if last_checkpoint != None:\n",
    "        checkpoint_number = re.search('cp-(\\d+).ckpt', last_checkpoint)\n",
    "        remaining_epochs = epochs - int(checkpoint_number.group(1))\n",
    "        i_epoch = int(checkpoint_number.group(1))\n",
    "        model.load_weights(last_checkpoint)\n",
    "        print(\"Restored model from epoch \", str(checkpoint_number.group(1)),\n",
    "              \", performing \", str(remaining_epochs), \" epochs:\")\n",
    "    if remaining_epochs > 0:\n",
    "        print(\"STARTING AT EPOCH \", i_epoch, \" performing \", epochs-i_epoch, \"epochs\")\n",
    "        model.fit(training_set, training_set, epochs=epochs, batch_size=32, shuffle=True, initial_epoch=i_epoch,\n",
    "                  validation_data=(testing_set, testing_set), verbose=1, callbacks=[checkpoint_callback])\n",
    "    print(\"model finished training\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "defining the loss function as mentioned in the HVRNNAE paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, inference_data):\n",
    "    # kb.clear_session()\n",
    "    output_mean = Model(inputs=model.input,\n",
    "                        outputs=model.get_layer('input_mean').output)\n",
    "    output_log_variance = Model(\n",
    "        inputs=model.input, outputs=model.get_layer('input_log_variance').output)\n",
    "    predictions = []\n",
    "    losses = []\n",
    "    #for data in inference_data:\n",
    "    #    inference_data = np.expand_dims(inference_data, axis=0)\n",
    "    current_prediction = model.predict(inference_data, batch_size=1,verbose=1)\n",
    "    predicted_output_mean = output_mean.predict(inference_data, batch_size=1)\n",
    "    predicted_log_variance = output_log_variance.predict(\n",
    "        inference_data, batch_size=1)\n",
    "    current_loss = loss(inference_data, current_prediction,\n",
    "                        predicted_output_mean, predicted_log_variance)\n",
    "    return current_loss\n",
    "    #losses.append(current_loss)\n",
    "    #return losses"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "defining the same sample function used in the same paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(falls, adl):\n",
    "    # we want to count total sample in falls < - this will always ALWAYS be less\n",
    "    count = 0\n",
    "    for key in falls.keys():\n",
    "        for sample in falls[key]:\n",
    "            count = count + 1\n",
    "    # now we want to see how many total activities are in the adl samples\n",
    "    total_number_of_activities = 0\n",
    "    for key in adl.keys():\n",
    "        total_number_of_activities = total_number_of_activities + 1\n",
    "    # to get the number of activities needed per sample we divide count by total number\n",
    "    samples_needed_per_adl = int(count/total_number_of_activities)\n",
    "    # to make this more fair i will randomly pick samples \n",
    "    print(samples_needed_per_adl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all():\n",
    "    raw_training_data = load_raw_data_sliding_window(ADL_Directories)       #\n",
    "    raw_testing_dta = load_raw_data_sliding_window(Falling_Directories)     #\n",
    "    training_map = generate_frame_sequences(raw_training_data)              #\n",
    "    testing_map = generate_frame_sequences(raw_testing_dta)                 #\n",
    "    compute_frame_statistics(training_map, testing_map)                     #\n",
    "    print_histogram()  \n",
    "\n",
    "    MAX_POINT_FRAME = retrieve_max()\n",
    "    MAX_POINT_FRAME = MAX_POINT_FRAME + (16 - (MAX_POINT_FRAME % 16))\n",
    "\n",
    "    train_map = {}\n",
    "    test_map = {}\n",
    "    for activity in ADL_Directories:\n",
    "        activity_samples = load_mmData([activity], \"Training_Set/\" + activity + \"/\" , Array_DIR_Train)\n",
    "        train_map[activity] = activity_samples\n",
    "\n",
    "    for activity in Falling_Directories:\n",
    "        activity_samples = load_mmData([activity], \"Testing_Set/\" + activity + \"/\" , Array_DIR_Test)\n",
    "        test_map[activity] = activity_samples    \n",
    "    \n",
    "    train_train1 = []\n",
    "    train_validation_train1 = []\n",
    "    train_validation_test1 = []\n",
    "    test1 = []\n",
    "    split_dataset(test_map, train_map)\n",
    "    for key in train_map.keys():\n",
    "        print(key)\n",
    "        train_train1.append(np.squeeze(train_map[key][0:int(len(train_map[key])*.80)]))\n",
    "        train_validation_train1.append(np.squeeze(train_map[key][int(len(train_map[key])*.80):int(len(train_map[key])*.90)]))\n",
    "        train_validation_test1.append(np.squeeze(train_map[key][int(len(train_map[key])*.90):]))\n",
    "\n",
    "    \n",
    "    for key in test_map.keys():\n",
    "        test1.append(np.squeeze(test_map[key]))\n",
    "\n",
    "    train_train = []\n",
    "    train_test = []\n",
    "    train_validation_train = []\n",
    "    train_validation_test = []\n",
    "    test = []\n",
    "    for key in train_train1:\n",
    "        for sample in key:\n",
    "            train_train.append(sample)\n",
    "    for key in train_validation_train1:\n",
    "        for sample in key:\n",
    "            train_validation_train.append(sample)   \n",
    "    for key in train_validation_test1:\n",
    "        for sample in key:\n",
    "            train_validation_test.append(sample)    \n",
    "    for key in test1:\n",
    "        for sample in key:\n",
    "            test.append(sample)         \n",
    "\n",
    "    return train_train, train_validation_train, train_validation_test, test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "verifying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    }
   ],
   "source": [
    "print(\"HI\")\n",
    "def save_train(path, data):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(path)\n",
    "    np.save(path + \"/data\", np.array(data), allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directories():\n",
    "    if(os.path.exists(Training_DIR +\"fall_youden_losses/\") is False or len(os.listdir(Training_DIR +\"fall_youden_losses/\")) != 1):\n",
    "        return False\n",
    "    if(os.path.exists(Training_DIR +\"no_fall_youden_losses/\") is False or len(os.listdir(Training_DIR +\"no_fall_youden_losses/\")) != 1):\n",
    "        return False\n",
    "    if(os.path.exists(Training_DIR +\"fall_validation_losses/\") is False or len(os.listdir(Training_DIR +\"fall_validation_losses/\")) != 1):\n",
    "        return False\n",
    "    if(os.path.exists(Training_DIR +\"no_fall_validation_losses/\") is False or len(os.listdir(Training_DIR +\"no_fall_validation_losses/\")) != 1):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The block below will perform the following for optimality sake\n",
    "# first it will check if the model has been trained AND has results --> having results in this case implies trained\n",
    "# if it finds the results saved already, it will simply load them immediately no need to re-run model through test cases we already have the result\n",
    "# if it finds ANY of the test cases are missing from the saved, it will re-run and save all results\n",
    "\n",
    "# in this block here we first train the model with the test set, then split the testing set for validation\n",
    "# we run the sample first through model, to get losses, and in end we return the losses for validation\n",
    "# 1. training set -> 10,10, 10% for getting youdin index, 10% for validating youdin index\n",
    "# 2. test set ->     50, 50, 50% for getting youdin index, 50% for validating youdin index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "Background\n",
      "Sit\n",
      "LayFloor\n",
      "Stand\n",
      "LayBed\n",
      "Walking\n",
      "Transition\n",
      "SitBed\n",
      "266\n",
      "316\n",
      "not crash\n",
      "(80636, 20, 272, 4)\n",
      "training_started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 02:41:32.236938: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST CHECKPOINT -   None\n",
      "STARTING AT EPOCH  0  performing  100 epochs\n",
      "Train on 80636 samples, validate on 80636 samples\n",
      "Epoch 1/100\n",
      "80608/80636 [============================>.] - ETA: 0s - loss: nan\n",
      "Epoch 00001: saving model to /srv/scratch/mmwave/Checkpoints/cp-0001.ckpt\n",
      "80636/80636 [==============================] - 79s 982us/sample - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "61952/80636 [======================>.......] - ETA: 11s - loss: nan"
     ]
    }
   ],
   "source": [
    "if check_directories() is False:\n",
    "    train_train, train_validation_train, train_validation_test, test = load_all()\n",
    "    MAX_POINT_FRAME = retrieve_max()\n",
    "    print(MAX_POINT_FRAME)\n",
    "    MAX_POINT_FRAME = MAX_POINT_FRAME + (16 - (MAX_POINT_FRAME % 16))\n",
    "    test_override = []\n",
    "    \n",
    "    for test_data in test:\n",
    "        if(len(test_data) > 0):\n",
    "            test_override.append(test_data)\n",
    "    test = test_override\n",
    "    print(len(test))\n",
    "\n",
    "#     train_override = []\n",
    "#     for train_data in test:\n",
    "#         if(len(train_data) > 0):\n",
    "#             train_override.append(train_data)\n",
    "#     train = train_override\n",
    "\n",
    "\n",
    "    # for training the model, we can just pass in 80% of samples as a flattened array, when we do testing we do sample by sample instead\n",
    "    train_split = []\n",
    "    # for train in train[int(len(train)*.80):]:\n",
    "    #    test.append(train)\n",
    "    # for training we flatten the split and validation\n",
    "    for train_data in train_train:\n",
    "        for data in train_data:\n",
    "            if(len(data) > 0):\n",
    "                if np.mean(data) < 9:\n",
    "                    train_split.append(np.array(data))\n",
    "                else:\n",
    "                    print(\"WTF LMAO MEAN OVER 9\")\n",
    "\n",
    "    print(\"not crash\")\n",
    "    fall_test_validation_youden = []\n",
    "    fall_test_validation = []\n",
    "\n",
    "    no_fall_test_validation_youden = []\n",
    "    no_fall_test_validation = []\n",
    "\n",
    "    for train_data in train_validation_train:\n",
    "        no_fall_test_validation_youden.append(train_data)   \n",
    "\n",
    "    for train_data in train_validation_test:\n",
    "        no_fall_test_validation.append(train_data)   \n",
    "\n",
    "    for test_data in test[: int(len(test)*.50)]:\n",
    "        fall_test_validation_youden.append(test_data)\n",
    "\n",
    "    for test_data in test[int(len(test)*.50):]:\n",
    "        fall_test_validation.append(test_data)\n",
    "\n",
    "    # for test validation, the first 20% of the array int(len(train)*0.2) is negative samples, remainder positive samples\n",
    "    del train_train\n",
    "    del train_validation_train\n",
    "    del train_validation_test\n",
    "    del test\n",
    "    print(np.shape(train_split))\n",
    "    \n",
    "    \n",
    "    model = train_HVRNNAE(np.array(train_split), np.array(train_split))\n",
    "    fall_youden_losses = []\n",
    "    no_fall_youden_losses = []\n",
    "    fall_validation_losses = []\n",
    "    no_fall_validation_losses = []\n",
    "\n",
    "    # we want to validate our model on test sample and save here, these will all be used for testing\n",
    "    # run data in model, save losses in file\n",
    "\n",
    "    for sample_data in fall_test_validation_youden:\n",
    "        if len(sample_data) == 0:\n",
    "            continue;\n",
    "        if len(np.shape(sample_data))!= 4:\n",
    "            sample_data = [sample_data]\n",
    "            sample_data = np.array(sample_data)\n",
    "        sample_losses = predict(model, sample_data)\n",
    "        fall_youden_losses.append(np.array(sample_losses)) \n",
    "    save_train(Training_DIR +\"fall_youden_losses/\", fall_youden_losses)\n",
    "    \n",
    "    for sample_data in no_fall_test_validation_youden:\n",
    "        if len(sample_data) == 0:\n",
    "            continue;\n",
    "        if len(np.shape(sample_data)) != 4:\n",
    "            sample_data = [sample_data]\n",
    "            sample_data = np.array(sample_data)\n",
    "        sample_losses = predict(model, sample_data)\n",
    "        no_fall_youden_losses.append(np.array(sample_losses))\n",
    "    save_train(Training_DIR +\"no_fall_youden_losses/\", no_fall_youden_losses)\n",
    "\n",
    "    for sample_data in fall_test_validation:\n",
    "        if len(sample_data) == 0:\n",
    "            continue;\n",
    "        if len(np.shape(sample_data)) != 4:\n",
    "            sample_data = [sample_data]\n",
    "            sample_data = np.array(sample_data)\n",
    "        sample_losses = predict(model, sample_data)\n",
    "        fall_validation_losses.append(np.array(sample_losses))\n",
    "    save_train(Training_DIR +\"fall_validation_losses/\", fall_validation_losses)\n",
    "\n",
    "    for sample_data in no_fall_test_validation:\n",
    "        if len(sample_data) == 0:\n",
    "            continue;\n",
    "        if len(np.shape(sample_data)) != 4:\n",
    "            sample_data = [sample_data]\n",
    "            sample_data = np.array(sample_data)\n",
    "        sample_losses = predict(model, sample_data)\n",
    "        no_fall_validation_losses.append(np.array(sample_losses))\n",
    "    save_train(Training_DIR +\"no_fall_validation_losses/\", no_fall_validation_losses)\n",
    "\n",
    "else:\n",
    "    fall_youden_losses = np.load(Training_DIR + \"fall_youden_losses/data.npy\", allow_pickle=True)\n",
    "    no_fall_youden_losses = np.load(Training_DIR + \"no_fall_youden_losses/data.npy\", allow_pickle=True)\n",
    "    fall_validation_losses = np.load(Training_DIR + \"fall_validation_losses/data.npy\", allow_pickle=True)\n",
    "    no_fall_validation_losses = np.load(Training_DIR + \"no_fall_validation_losses/data.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(fall_youden_losses)\n",
    "# plt.hist(no_fall_youden_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the losses out in this cell here\n",
    "# print(\"-------------------------- FALL LOSSES --------------------------\")\n",
    "# print(fall_youden_losses)\n",
    "# print(fall_validation_losses)\n",
    "# print(\"\\n\\n\\n-------------------------- NO FALL LOSSES --------------------------\")\n",
    "\n",
    "# print(no_fall_youden_losses)\n",
    "# print(no_fall_validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FallValdLossesAll = np.empty((0,))\n",
    "for i in range(len(fall_validation_losses)):\n",
    "    FallValdLossesAll = np.concatenate((FallValdLossesAll,fall_validation_losses[i]))\n",
    "FallValdLossesAll = np.asarray(FallValdLossesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FallTrainLossesAll = np.empty((0,))\n",
    "for i in range(len(fall_youden_losses)):\n",
    "    FallTrainLossesAll = np.concatenate((FallTrainLossesAll,fall_youden_losses[i]))\n",
    "FallTrainLossesAll = np.asarray(FallTrainLossesAll)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoFallValdLossesAll = np.empty((0,))\n",
    "for i in range(len(no_fall_validation_losses)):\n",
    "    NoFallValdLossesAll = np.concatenate((NoFallValdLossesAll,no_fall_validation_losses[i]))\n",
    "NoFallValdLossesAll = np.asarray(NoFallValdLossesAll)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoFallTrainLossesAll = np.empty((0,))\n",
    "for i in range(len(no_fall_youden_losses)):\n",
    "    NoFallTrainLossesAll = np.concatenate((NoFallTrainLossesAll,no_fall_youden_losses[i]))\n",
    "NoFallTrainLossesAll = np.asarray(NoFallTrainLossesAll) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoFallTrainLossesAllSort = np.sort(NoFallTrainLossesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(FallValdLossesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(NoFallTrainLossesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(FallValdLossesAll)\n",
    "# plt.hist(NoFallValdLossesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NoFallTrainLossesAllSort.shape[0]\n",
    "TPR = []\n",
    "FPR = []\n",
    "for k in range(N-1):\n",
    "    TPR.append(np.sum(NoFallValdLossesAll>=NoFallTrainLossesAllSort[k])/(NoFallValdLossesAll.shape[0]))\n",
    "    FPR.append(np.sum(FallValdLossesAll>=NoFallTrainLossesAllSort[k])/(FallValdLossesAll.shape[0]))\n",
    "TPR = np.asarray(TPR)\n",
    "FPR = np.asarray(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(FPR,TPR)\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Youdin = TPR-FPR\n",
    "maxYoudinInd = np.where(Youdin == np.max(Youdin))\n",
    "threshold = np.max(Youdin)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(NoFallValdLossesAll)\n",
    "plt.hist(FallValdLossesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TPR[maxYoudinInd])\n",
    "print(FPR[maxYoudinInd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cases = fall_youden_losses\n",
    "negative_cases = no_fall_youden_losses\n",
    "validation_positive_cases = fall_validation_losses\n",
    "validation_negative_cases = no_fall_validation_losses\n",
    "\n",
    "all_cases = []\n",
    "all_positive_cases = []\n",
    "all_negative_cases = []\n",
    "\n",
    "# each of the positive cases consist of a sample, each sample can be seen as a bunch of losses\n",
    "# [61, 60, 374, 4] -> whole thing = 1 activity, the 61 losses for each sample are just 1 float value\n",
    "# we want to extract each sample loss into an overall array for youdin index calculation\n",
    "for positive_case in positive_cases:\n",
    "    for sample in positive_case:\n",
    "        all_cases.append(sample)\n",
    "        all_positive_cases.append(sample)\n",
    "\n",
    "for negative_case in negative_cases:\n",
    "    for sample in negative_case:\n",
    "        all_cases.append(sample)\n",
    "        all_positive_cases.append(sample)\n",
    "all_cases_sorted = np.sort(all_cases)\n",
    "# here we will find the youden index to find a suitable threshold, then test it on the validation set\n",
    "N = all_cases_sorted.shape[0]\n",
    "print(max(all_cases_sorted))\n",
    "TPR = []\n",
    "FPR = []\n",
    "\n",
    "# sum all losses where the value is smaller than the index we are looking at, and divide by total number of positive cases\n",
    "# do same for the negative\n",
    "# we then add these into our TPR and FPR arrays\n",
    "# next we want to subtract FPR from the TPR, and find the maximum value -> gives us the threhold.\n",
    "\n",
    "# current issue somewhere here? ???? HEH\n",
    "for k in range(N):\n",
    "    positive_sum_to_insert = np.sum(all_positive_cases < all_cases_sorted[k])/(len(all_positive_cases))\n",
    "    negative_sum_to_insert = np.sum(all_negative_cases < all_cases_sorted[k])/(len(all_negative_cases))\n",
    "    TPR.append(positive_sum_to_insert)\n",
    "    FPR.append(negative_sum_to_insert)\n",
    "# print(TPR)\n",
    "# print(FPR)\n",
    "youdin =  np.array(TPR) - np.array(FPR)\n",
    "youdin = youdin\n",
    "threshold = np.max(youdin)\n",
    "print(youdin)\n",
    "# max_youdin_index = (np.where(youdin == np.max(youdin))[0][0])\n",
    "# now to test accuracy of the model on unseen data\n",
    "fall_sample_count = len(fall_validation_losses)\n",
    "no_fall_sample_count = len(no_fall_validation_losses)\n",
    "\n",
    "\n",
    "y_predicted = []\n",
    "y_true = []\n",
    "falls_predicted_true = 0\n",
    "threshold = 0.0000004\n",
    "for sample in fall_validation_losses:\n",
    "    y_true.append(1)\n",
    "    fall = False\n",
    "    for data in sample:\n",
    "        if data >= threshold:\n",
    "            falls_predicted_true = falls_predicted_true + 1\n",
    "            fall = True\n",
    "            break\n",
    "    if fall == True:\n",
    "        y_predicted.append(1)\n",
    "    else:\n",
    "        y_predicted.append(0)\n",
    "\n",
    "\n",
    "no_fall_predicted_false = 0\n",
    "for sample in no_fall_validation_losses:\n",
    "    fall = False;\n",
    "    y_true.append(0)\n",
    "    for data in sample:\n",
    "        if data >= threshold:\n",
    "            no_fall_predicted_false = no_fall_predicted_false + 1\n",
    "            fall = True\n",
    "            break\n",
    "    if fall == True:\n",
    "        y_predicted.append(1)\n",
    "    else:\n",
    "        y_predicted.append(0)\n",
    "        \n",
    "print(falls_predicted_true/fall_sample_count*100, \" = percentage of falls predicted correctly\")\n",
    "print(((no_fall_sample_count - no_fall_predicted_false)*100)/no_fall_sample_count, \" = percentage of no-falls predicted correctly\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.utils.vis_utils import \n",
    "# from importlib import reload\n",
    "# reload(keras.utils.vis_utils)\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import plot_model   \n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss  \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1 = fall\n",
    "# 0 = ADL\n",
    "falls_predicted = []\n",
    "falls_true = []\n",
    "\n",
    "ADL_predicted = []\n",
    "ADL_true = []\n",
    "all_true = y_true\n",
    "all_predicted = y_predicted\n",
    "for i in range(len(y_predicted)):\n",
    "    if(y_true[i] == 1):\n",
    "        falls_predicted.append(y_predicted[i])\n",
    "        falls_true.append(y_true[i])\n",
    "    else:\n",
    "        ADL_predicted.append(y_predicted[i])\n",
    "        ADL_true.append(y_true[i])\n",
    "\n",
    "RocCurveDisplay.from_predictions(all_true, all_predicted)\n",
    "\n",
    "f1_score = f1_score(all_true, all_predicted, average='binary')\n",
    "precision_recall = precision_recall_fscore_support(all_true, all_predicted, average='binary',)\n",
    "acc_fall = accuracy_score(falls_true, falls_predicted)\n",
    "acc_adl = accuracy_score(ADL_true, ADL_predicted)\n",
    "acc_all = accuracy_score(all_true, all_predicted)\n",
    "log_losses = log_loss(all_true, all_predicted)\n",
    "auc = roc_auc_score(all_true, all_predicted)\n",
    "print(\"F1 Scores:\", f1_scores)\n",
    "print(\"precision, recall: \", precision_recall)\n",
    "print(\"fall accuracy: \", acc_fall, \"\\nADL accuracy: \", acc_adl,\"\\ntotal_accuracy: \", acc_all)\n",
    "print(\"log loss: \", log_losses)\n",
    "print(\"auc: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmWave",
   "language": "python",
   "name": "mmwave"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
